{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Path: /home/polaris/.galapy\n",
      "\n",
      "l68\n",
      "347660922309852\n",
      "HST.WFPC2.WF.F547M\n",
      "HST.WFC3.UVIS2.F275W\n",
      "HST.WFC3.UVIS2.F350LP\n",
      "HST.WFC3.UVIS2.F475X\n",
      "HST.WFC3.UVIS2.F390W\n",
      "HST.WFC3.UVIS2.F225W\n",
      "HST.WFC3.UVIS2.F606W\n",
      "HST.WFC3.UVIS2.F600LP\n",
      "HST.WFC3.UVIS2.F336W\n",
      "HST.WFC3.IR.F105W\n",
      "HST.WFC3.IR.F110W\n",
      "HST.WFC3.IR.F098M\n",
      "HST.WFC3.IR.F160W\n",
      "HST.ACS.WFC.F625W\n",
      "JCMT.SCUBA.2450MHz\n",
      "JCMT.SCUBA.2850MHz\n",
      "CFHT.MegaCam.u_1\n",
      "ATCA.ATCA2\n",
      "ATCA.ATCA1\n",
      "GOODS.z\n",
      "GOODS.b\n",
      "GOODS.v\n",
      "GOODS.i\n",
      "UKIDSS.Y\n",
      "WISE.W3\n",
      "WISE.W4\n",
      "WISE.W2\n",
      "WISE.W1\n",
      "2MASS.H\n",
      "2MASS.J\n",
      "2MASS.Ks\n",
      "ALMA.B8\n",
      "ALMA.B6\n",
      "ALMA.B7\n",
      "ALMA.B3\n",
      "GALEX.FUV\n",
      "GALEX.NUV\n",
      "Subaru.HSC.z_filter\n",
      "Subaru.HSC.i_filter\n",
      "Subaru.HSC.r_filter\n",
      "Subaru.Suprime.B_filter\n",
      "Subaru.Suprime.V_filter\n",
      "Spitzer.IRAC.I3\n",
      "Spitzer.IRAC.I2\n",
      "Spitzer.IRAC.I1\n",
      "Spitzer.IRAC.I4\n",
      "Spitzer.MIPS.160mu\n",
      "Spitzer.MIPS.24mu\n",
      "Spitzer.MIPS.70mu\n",
      "Spitzer.IRS.Red\n",
      "Spitzer.IRS.Blue\n",
      "JWST.NIRISS.F115W\n",
      "JWST.NIRISS.F150W\n",
      "JWST.NIRISS.F430M\n",
      "JWST.NIRISS.F480M\n",
      "JWST.NIRISS.F356W\n",
      "JWST.NIRISS.F140M\n",
      "JWST.NIRISS.F090W\n",
      "JWST.NIRISS.F444W\n",
      "JWST.NIRISS.F200W\n",
      "JWST.NIRISS.F277W\n",
      "JWST.NIRISS.F380M\n",
      "JWST.NIRISS.F158M\n",
      "JWST.MIRI.F770W\n",
      "JWST.MIRI.F1280W\n",
      "JWST.MIRI.F1130W\n",
      "JWST.MIRI.F560W\n",
      "JWST.MIRI.F1500W\n",
      "JWST.MIRI.F1000W\n",
      "JWST.MIRI.F2550W\n",
      "JWST.MIRI.F1800W\n",
      "JWST.MIRI.F2100W\n",
      "JWST.NIRCam.F115W\n",
      "JWST.NIRCam.F322W2\n",
      "JWST.NIRCam.F210M\n",
      "JWST.NIRCam.F150W\n",
      "JWST.NIRCam.F182M\n",
      "JWST.NIRCam.F430M\n",
      "JWST.NIRCam.F187N\n",
      "JWST.NIRCam.F480M\n",
      "JWST.NIRCam.F070W\n",
      "JWST.NIRCam.F212N\n",
      "JWST.NIRCam.F356W\n",
      "JWST.NIRCam.F140M\n",
      "JWST.NIRCam.F410M\n",
      "JWST.NIRCam.F090W\n",
      "JWST.NIRCam.F335M\n",
      "JWST.NIRCam.F300M\n",
      "JWST.NIRCam.F444W\n",
      "JWST.NIRCam.F200W\n",
      "JWST.NIRCam.F460M\n",
      "JWST.NIRCam.F150W2\n",
      "JWST.NIRCam.F323N\n",
      "JWST.NIRCam.F466N\n",
      "JWST.NIRCam.F470N\n",
      "JWST.NIRCam.F405N\n",
      "JWST.NIRCam.F360M\n",
      "JWST.NIRCam.F164N\n",
      "JWST.NIRCam.F277W\n",
      "JWST.NIRCam.F162M\n",
      "JWST.NIRCam.F250M\n",
      "Paranal.VISTA.J_filter\n",
      "Paranal.VISTA.Z_filter\n",
      "Paranal.VISTA.Ks_filter\n",
      "Paranal.VISTA.Y_filter\n",
      "Paranal.VISTA.H_filter\n",
      "CTIO.DECAM.Y\n",
      "CTIO.DECAM.r\n",
      "CTIO.DECAM.g\n",
      "CTIO.DECAM.z\n",
      "CTIO.DECAM.u\n",
      "CTIO.DECAM.i\n",
      "VLA.X\n",
      "VLA.C\n",
      "VLA.L\n",
      "Herschel.PACS.blue\n",
      "Herschel.PACS.red\n",
      "Herschel.PACS.green\n",
      "Herschel.SPIRE.PMW\n",
      "Herschel.SPIRE.PLW\n",
      "Herschel.SPIRE.PSW\n",
      "SDSS.r\n",
      "SDSS.g\n",
      "SDSS.z\n",
      "SDSS.u\n",
      "SDSS.i\n"
     ]
    }
   ],
   "source": [
    "from galapy.PhotometricSystem import print_filters\n",
    "print_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the multiwavelenght catalog to keep only the columns needed\n",
    "emu_columns = [ 'EMU_ra_deg_cont', 'EMU_dec_deg_cont']\n",
    "\n",
    "# desdr2_mag = ['DES_mag_auto_g_dered', 'DES_mag_auto_r_dered', 'DES_mag_auto_i_dered', 'DES_mag_auto_z_dered']\n",
    "# desdr2_colors = ['DES_g_r_dered', 'DES_r_i_dered', 'DES_i_z_dered']\n",
    "\n",
    "# Technically only need one magnitude to recover the rest from the colors\n",
    "desy6gold_mag = ['DESY6_mag_auto_g_extcorr', 'DESY6_mag_auto_r_extcorr', 'DESY6_mag_auto_i_extcorr', 'DESY6_mag_auto_z_extcorr', 'DESY6_mag_auto_y_extcorr']\n",
    "desy6gold_colors = ['DESY6_g_r_extcorr', 'DESY6_r_i_extcorr', 'DESY6_i_z_extcorr', 'DESY6_z_y_extcorr']\n",
    "desy6gold_features = ['DESY6_dnf_z', 'DESY6_spread_model_g', 'DESY6_spread_model_r', 'DESY6_spread_model_i', 'DESY6_spread_model_z']\n",
    "\n",
    "viking_mag = ['VKG_zAperMag3_ab_extcorr', 'VKG_jAperMag3_ab_extcorr', 'VKG_yAperMag3_ab_extcorr', 'VKG_ksAperMag3_ab_extcorr', 'VKG_hAperMag3_ab_extcorr']\n",
    "viking_colors = ['VKG_z_y_am3_extcorr', 'VKG_y_j_am3_extcorr', 'VKG_j_h_am3_extcorr', 'VKG_h_ks_am3_extcorr']\n",
    "viking_features = ['VKG_mergedClassStat']\n",
    "\n",
    "catwise_mag = ['CAT_w1mpro_ab', 'CAT_w2mpro_ab']\n",
    "catwise_colors = ['CAT_w1_w2_ab']\n",
    "\n",
    "colors = desy6gold_colors + viking_colors + catwise_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Error (QE) and Topographic Error (TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization Error (QE)\n",
    "# Average distance of a data point to the nearest lattice node\n",
    "# Measures how well the mapping fits the distribution of the data\n",
    "\n",
    "def som_quantization_error(data, trained_som):\n",
    "    '''\n",
    "    Calculates the quantization error of a trained SOMNet object\n",
    "\n",
    "    Args:\n",
    "        data: NumPy array of input data.\n",
    "        trainded_som: trained SimpSOM SOMNet object\n",
    "\n",
    "    Returns:\n",
    "        quantization error (float)\n",
    "    '''\n",
    "    # Convert to clean NumPy array with uniform dtype first\n",
    "    data_np = np.asarray(data, dtype=np.float64)\n",
    "\n",
    "    # Convert NumPy array to CuPy array for GPU processing\n",
    "    data_cp = cp.array(data_np)\n",
    "\n",
    "    # Find all BMU indices\n",
    "    bmu_indices = trained_som.find_bmu_ix(data_cp)\n",
    "\n",
    "    # Get the weights of the BMUs\n",
    "    bmu_weights = cp.array([trained_som.nodes_list[int(bmu_idx)].weights for bmu_idx in bmu_indices])\n",
    "\n",
    "    # Vectorized distance calculation\n",
    "    distances = cp.linalg.norm(bmu_weights - data_cp, axis=1)\n",
    "    total_distance = cp.sum(distances)\n",
    "\n",
    "    quantization_error = float(total_distance / len(data))\n",
    "    return quantization_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topographic Error (TE)\n",
    "# Proportion of data points whose BMU and second BMU are NOT neighbors\n",
    "# Measures how well the shape of the data is preserved in the output space\n",
    "\n",
    "def som_topographic_error(data, trained_som):\n",
    "    \"\"\"\n",
    "    Computes topographic error ET for a SOM with hex topology using GPU (CuPy).\n",
    "    \n",
    "    Args:\n",
    "        data:    The input data used to train the SOM (NumPy array).\n",
    "        trained_som: A trained SOMNet object from the simpsom library.\n",
    "\n",
    "    Returns:\n",
    "        Topographic error (float between 0 and 1).\n",
    "        Proportion of data points whose BMU and second BMU are NOT neighbors\n",
    "    \"\"\"\n",
    "    # Convert data to CuPy arrays\n",
    "    data_cp = cp.array(data)\n",
    "\n",
    "    # Get all the nodes' weights from the trained SOM (GPU-enabled)\n",
    "    weights_cp = cp.array([node.weights for node in trained_som.nodes_list])\n",
    "\n",
    "    # Initialize total error\n",
    "    total_error = 0\n",
    "\n",
    "    # Find all BMU indices\n",
    "    bmu_indices = trained_som.find_bmu_ix(data_cp)\n",
    "\n",
    "    # Find all the second BMU indices\n",
    "    som_dist = sps.distances.Distance(xp=np) # Initialize the distance object, as required by the documentation\n",
    "    distances = som_dist.pairdist(data_cp, weights_cp, metric='euclidean')\n",
    "\n",
    "    sorted_indices = cp.argsort(distances, axis=1)\n",
    "    sbmu_indices = sorted_indices[:, 1]\n",
    "\n",
    "\n",
    "    # Get the positions of the BMU and second BMU in the grid\n",
    "    bmu_positions = cp.array([trained_som.nodes_list[int(bmu_idx)].pos for bmu_idx in bmu_indices])\n",
    "    sbmu_positions = cp.array([trained_som.nodes_list[int(sbmu_idx)].pos for sbmu_idx in sbmu_indices])\n",
    "\n",
    "\n",
    "    bmu_row, bmu_col = bmu_positions[:, 0], bmu_positions[:, 1]\n",
    "    sbmu_row, sbmu_col = sbmu_positions[:, 0], sbmu_positions[:, 1]\n",
    "\n",
    "    # Check if BMU and sBMU are neighbors\n",
    "    row_neighbors = cp.abs(bmu_row - sbmu_row)\n",
    "    col_neighbors = cp.abs(bmu_col - sbmu_col)\n",
    "\n",
    "    not_neighbors = (row_neighbors > 1) | (col_neighbors > 1)\n",
    "\n",
    "    number_not_neighbors = cp.sum(not_neighbors)\n",
    "\n",
    "    # Compute the topographic error\n",
    "    topographic_error = number_not_neighbors / data_cp.shape[0]\n",
    "\n",
    "    return float(topographic_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add custom DES filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_filter_path = '/data/mfonseca/survey_data/DES_data/CTIO_DECam.g.dat'\n",
    "i_filter_path = '/data/mfonseca/survey_data/DES_data/CTIO_DECam.i.dat'\n",
    "r_filter_path = '/data/mfonseca/survey_data/DES_data/CTIO_DECam.r.dat'\n",
    "z_filter_path = '/data/mfonseca/survey_data/DES_data/CTIO_DECam.z.dat'\n",
    "y_filter_path = '/data/mfonseca/survey_data/DES_data/CTIO_DECam.Y.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_filter_data(input_filename, output_filename):\n",
    "    \"\"\"\n",
    "    Normalizes the second column (transmission values) of a .dat file.\n",
    "\n",
    "    Parameters:\n",
    "    - input_filename (str): Path to the input .dat file.\n",
    "    - output_filename (str): Path where the normalized data will be saved.\n",
    "\n",
    "    The input file should contain two columns: wavelength (first column) and transmission (second column).\n",
    "    \"\"\"\n",
    "    # Initialize lists to store data\n",
    "    lambda_values = []\n",
    "    transmission_values = []\n",
    "\n",
    "    # Read the data from the .dat file\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # Skip comments or empty lines\n",
    "            if line.startswith('#') or line.strip() == '':\n",
    "                continue\n",
    "            \n",
    "            # Split the line into wavelength and transmission\n",
    "            columns = line.split()\n",
    "            lambda_values.append(float(columns[0]))  # Wavelength (first column)\n",
    "            transmission_values.append(float(columns[1]))  # Transmission (second column)\n",
    "\n",
    "    # Convert the lists to numpy arrays for easier processing\n",
    "    lambda_values = np.array(lambda_values)\n",
    "    transmission_values = np.array(transmission_values)\n",
    "\n",
    "    # Normalize the transmission values (second column)\n",
    "    max_transmission = np.max(transmission_values)\n",
    "    normalized_transmission = transmission_values / max_transmission\n",
    "\n",
    "    # Save the normalized data to the output .dat file\n",
    "    with open(output_filename, 'w') as f:\n",
    "        # Optionally add a header\n",
    "        f.write(\"# Wavelength (Å) and Normalized Transmission Values\\n\")\n",
    "        \n",
    "        # Write the wavelength and the normalized transmission\n",
    "        for lambda_val, norm_trans in zip(lambda_values, normalized_transmission):\n",
    "            f.write(f\"{lambda_val} {norm_trans}\\n\")\n",
    "\n",
    "    print(f\"Normalization complete. Output saved to {output_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize_filter_data(g_filter_path, g_filter_path)\n",
    "# normalize_filter_data(i_filter_path, i_filter_path)\n",
    "# normalize_filter_data(r_filter_path, r_filter_path)\n",
    "# normalize_filter_data(y_filter_path, y_filter_path)\n",
    "# normalize_filter_data(z_filter_path, z_filter_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labastro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
