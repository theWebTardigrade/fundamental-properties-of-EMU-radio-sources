{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6942eac",
   "metadata": {},
   "source": [
    "# Self Organized Maps (SOMs) for DES/VIKING/CATWISE objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730eeb3",
   "metadata": {},
   "source": [
    "## Define the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "observatory = '/data/mfonseca/'\n",
    "my_computer = '/home/polaris/Lab_Astro/data/'\n",
    "\n",
    "directory = my_computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72afb7a",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SimpSOM, https://simpsom.readthedocs.io\n",
    "import simpsom as sps\n",
    "\n",
    "# Astropy\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "# CuPY\n",
    "# import cupy as cp\n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Kolmorgorov-Smirnov\n",
    "from scipy.stats import kstest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef03e0",
   "metadata": {},
   "source": [
    "## PCA Whitening and ZPCA Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_whitening(data, epsilon=1e-5):\n",
    "    '''\n",
    "    PCA whitening\n",
    "\n",
    "    Args:\n",
    "        data: array-like data\n",
    "        epsilon: small value to avoid division by zero\n",
    "\n",
    "    Returns:\n",
    "        out: array-like data pca whitened\n",
    "    \n",
    "    '''\n",
    "    # Data needs to have 0 mean\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    data_centered = data - data_mean\n",
    "\n",
    "    # If the data has 0 mean, then we calculate the covariance matrix\n",
    "    # rowvar=False means that each row is an observation\n",
    "    cov_matrix = np.cov(data_centered, rowvar=False)\n",
    "\n",
    "    # Calculate the eigenvalues and the eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "\n",
    "  \n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals + epsilon))\n",
    "    whitening_matrix = eigvecs @ D_inv_sqrt @ eigvecs.T\n",
    "\n",
    "    xPCAwhite = (whitening_matrix @ data_centered.T).T\n",
    "\n",
    "    return xPCAwhite\n",
    "\n",
    "\n",
    "def zca_whitening(data, epsilon=1e-5):\n",
    "    '''\n",
    "    ZCA whitening\n",
    "    \n",
    "    Args:\n",
    "        data: array-like data\n",
    "        epsilon: small value to avoid division by zero\n",
    "\n",
    "    Returns:\n",
    "        out: array-like data zca whitened\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # Data needs to have 0 mean\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    data_mean0 = data - data_mean\n",
    "\n",
    "    # If the data has 0 mean, then we calculate the covariance matrix\n",
    "    # rowvar=False means that each row is an observation\n",
    "    cov_matrix = np.cov(data_mean0, rowvar=False)\n",
    "\n",
    "    # Calculate the eigenvalues and the eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "\n",
    "    # Calculate x_rot and x_tilde\n",
    "    x_rot = np.dot(data_mean0, eigvecs)\n",
    "\n",
    "    # Whitening matrix: U * D^{-1/2} * U.T\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals + epsilon))\n",
    "    whitening_matrix = eigvecs @ D_inv_sqrt @ eigvecs.T\n",
    "\n",
    "    # Apply whitening\n",
    "    xZCAwhite = data_mean0 @ whitening_matrix\n",
    "    \n",
    "    return xZCAwhite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5605e76e",
   "metadata": {},
   "source": [
    "## PCA Dewhitening and ZCA Dewhitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pca_whitening(original_data, whitened_data, epsilon=1e-5):\n",
    "    '''\n",
    "    Inverse PCA whitening\n",
    "\n",
    "    Args:\n",
    "        original_data: original data\n",
    "        whitened_data: whitened data\n",
    "        epsilon: small value to avoid division by zero\n",
    "\n",
    "    Returns:\n",
    "        out: array-like data in original feature space\n",
    "    \n",
    "    '''\n",
    "    # Data needs to have 0 mean\n",
    "    data_mean = np.mean(original_data, axis=0)\n",
    "    data_centered = original_data - data_mean\n",
    "\n",
    "    # If the data has 0 mean, then we calculate the covariance matrix\n",
    "    # rowvar=False means that each row is an observation\n",
    "    cov_matrix = np.cov(data_centered, rowvar=False)\n",
    "\n",
    "    # Calculate the eigenvalues and the eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "\n",
    "    D_sqrt = np.diag(np.sqrt(eigvals + epsilon))\n",
    "\n",
    "    \n",
    "    # Calculate the inverse of the PCA whitening matrix\n",
    "    X_centered = whitened_data @ ((eigvecs @ D_sqrt @ eigvecs.T))\n",
    "    \n",
    "    x_dewhitened = X_centered + data_mean.values\n",
    "\n",
    "    return x_dewhitened\n",
    "\n",
    "\n",
    "def inverse_zca_whitening(original_data, whitened_data, epsilon=1e-5):\n",
    "    '''\n",
    "    Inverse ZCA whitening\n",
    "    \n",
    "    Args:\n",
    "        data: array-like data\n",
    "        epsilon: small value to avoid division by zero\n",
    "\n",
    "    Returns:\n",
    "        out: array-like data in original feature space\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # Data needs to have 0 mean\n",
    "    data_mean = np.mean(original_data, axis=0)\n",
    "    data_mean0 = original_data - data_mean\n",
    "\n",
    "    # If the data has 0 mean, then we calculate the covariance matrix\n",
    "    # rowvar=False means that each row is an observation\n",
    "    cov_matrix = np.cov(data_mean0, rowvar=False)\n",
    "\n",
    "    # Calculate the eigenvalues and the eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "\n",
    "    # Calculate the inverse of the ZCA whitening matrix\n",
    "    D = np.diag(np.sqrt(eigvals + epsilon))\n",
    "    inverse_zca_matrix = eigvecs @ D @ eigvecs.T\n",
    "\n",
    "    # Apply inverse transform and add mean back\n",
    "    x_orig = (inverse_zca_matrix @ whitened_data.T).T + data_mean.values\n",
    "\n",
    "    return x_orig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4a3ca",
   "metadata": {},
   "source": [
    "# Import DES + VIKING + CATWISE match catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6125784",
   "metadata": {},
   "source": [
    "Import the matched catalog from NWAY and convert it to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3985f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RADIUS (3''), DESY6GOLD (0.1''), VIKINGDR4 (0.1''), CATWISE2020 (0.2''), No MAGNITUDES\n",
    "# For a false detection rate of <10% \n",
    "# p_i>=0.1 & match_flag==1 & p_any>0.83\n",
    "matched_no_mags_path = directory + 'cross_match/DESY6GOLD_VIKING_CATWISE_noMags/DESY6GOLD_VIKINGDR5_CATWISE_noMag.fits'\n",
    "matched_no_mags = Table.read(matched_no_mags_path)\n",
    "matched_no_mags = matched_no_mags.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842940c5",
   "metadata": {},
   "source": [
    "Filter using NWAY recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we filter the NWAY catalog to keep only the best objects\n",
    "\n",
    "# From NWAY\n",
    "# Filter the catalog based on the match_flag and p_i, p_any values\n",
    "match_mask = (matched_no_mags['match_flag'] == ) & (matched_no_mags['p_i'] >= ) & (matched_no_mags['p_any'] >= )\n",
    "catalog_matches_noMags = matched_no_mags[match_mask]\n",
    "print(f'Number of objects in the catalog {len(catalog_matches_noMags)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726e7cd",
   "metadata": {},
   "source": [
    "Select the objects that have matches in the two surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93978215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we select objects that have matches in all three surveys\n",
    "full_match_mask = ((catalog_matches_noMags['VKG_sourceID'] != -99) & (catalog_matches_noMags['CAT_source_id'] != b'-99'))\n",
    "catalog_matches_noMags_full = catalog_matches_noMags[full_match_mask]\n",
    "print(f'Number of objects in the catalog that have matches in the two surveys {len(catalog_matches_noMags_full)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f586d",
   "metadata": {},
   "source": [
    "Select the features used in the SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_columns = ['DESY6_mag_auto_g_extcorr',\n",
    "                   'VKG_mag_petro_y_ab_extcorr',\n",
    "                   'CAT_w1mpro_ab',\n",
    "                   'DESY6_g_r_extcorr', \n",
    "                   'DESY6_r_i_extcorr', \n",
    "                   'DESY6_i_z_extcorr', \n",
    "                   'VKG_y_j_petro_extcorr', \n",
    "                   'VKG_j_h_petro_extcorr', \n",
    "                   'VKG_h_ks_petro_extcorr', \n",
    "                   'CAT_w1_w2_ab', \n",
    "                   'DESY6_spread_model_g']\n",
    "\n",
    "catalog_som = catalog_matches_noMags_full[som_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6801dd",
   "metadata": {},
   "source": [
    "Filter for objects that have full photometric coverage in all the bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the photometric values that weren't detected are nans\n",
    "catalog_som = catalog_som.dropna()\n",
    "\n",
    "print(len(catalog_som))\n",
    "catalog_som.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926addf",
   "metadata": {},
   "source": [
    "# Perform ZCA Whitening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670abf9d",
   "metadata": {},
   "source": [
    "Correlation matrix for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_original = catalog_som.corr(method='pearson')\n",
    "plt.figure(figsize = (9,8))\n",
    "sns.heatmap(correlation_matrix_original, annot=True, fmt=\".2f\", cmap='coolwarm', center=0, square=True,\n",
    "            linewidths=0.5, cbar_kws={\"shrink\": 0.75})\n",
    "\n",
    "plt.title(\"Pearson Correlation Matrix for Original Data\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4771ce",
   "metadata": {},
   "source": [
    "Correlation matrix for ZCA whitened data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original training data to an CSV file for easier access\n",
    "data_path = '/home/polaris/Lab_Astro/data/soms/maps1/EMU_0102-32_DESY6GOLD_VIKINGDR5_CATWISE_noMag_original.csv'\n",
    "data.to_csv(data_path, index=False)\n",
    "\n",
    "\n",
    "# ZCA Whiten the data\n",
    "data_white = zca_whitening(data)\n",
    "\n",
    "# Keep the column labels\n",
    "data_white.columns = som_columns[:data_white.shape[1]]\n",
    "\n",
    "# Save the ZCA Whitened to an CSV file for easier access\n",
    "data_white_path = '/home/polaris/Lab_Astro/data/soms/maps1/EMU_0102-32_DESY6GOLD_VIKINGDR5_CATWISE_noMag_zcaWhite.csv'\n",
    "data_white.to_csv(data_white_path, index=False)\n",
    "\n",
    "# Calculate and plot the correlation matrix for the ZCA Whitened data\n",
    "correlation_matrix_whitened = data_white.corr(method='pearson')\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correlation_matrix_whitened, annot=True, fmt=\".2f\", cmap='coolwarm', center=0, square=True,\n",
    "            linewidths=0.5, cbar_kws={\"shrink\": 0.75})\n",
    "\n",
    "plt.title(\"Pearson Correlation Matrix ZCA Whitened Data\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e730f3a",
   "metadata": {},
   "source": [
    "# Generate the SOMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab520f",
   "metadata": {},
   "source": [
    "## Define the SOM topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOM topology (lattice size)\n",
    "\n",
    "data_white = np.array(data_white)\n",
    "\n",
    "# Number of sources in our dataframe\n",
    "inputdata_size = len(data_white)\n",
    "\n",
    "# From Kohonen, the optimal ratio of height to width of the lattice\n",
    "# is equal to the ratio of the two largest eigenvalue of the autocorrelation matrix\n",
    "cov_matrix = np.cov(data_white, rowvar=False)\n",
    "eigen_values = np.linalg.eigvals(cov_matrix)\n",
    "eigen_values_sorted = np.sort(eigen_values)[::-1]\n",
    "ratio_eigenvalues = eigen_values_sorted[0] / eigen_values_sorted[1]\n",
    "\n",
    "# From Kohonen, the number of nodes is 5*sqrt(n), where n is the number of data points\n",
    "som_dim = int(np.sqrt(inputdata_size) * 5)\n",
    "\n",
    "# The number of nodes in the x and y direction\n",
    "som_x = int(np.sqrt(som_dim * ratio_eigenvalues))\n",
    "som_y = int(som_x / ratio_eigenvalues)\n",
    "\n",
    "#=================================================================\n",
    "\n",
    "# Resize the SOM map by applying a scaling factor that maintains the aspect ratio\n",
    "\n",
    "scaling_factor = 2  # Change this factor to resize the map\n",
    "\n",
    "# Apply scaling to the x dimension, and calculate y dimension based on ratio\n",
    "som_x_resized = int(som_x * scaling_factor)\n",
    "som_y_resized = int(som_x_resized / ratio_eigenvalues)  # Keep the same ratio of eigenvalues\n",
    "\n",
    "#=================================================================\n",
    "\n",
    "# Print the results\n",
    "print('Dimension of the SOM: ', som_dim)\n",
    "print('Square SOM map size ', np.round(np.sqrt(som_dim)))\n",
    "print('Ratio of the two largest eigenvalues: ', int(ratio_eigenvalues))\n",
    "print('SOM map size using eigenvalues: ', som_x, 'x', som_y)\n",
    "\n",
    "print('Resized SOM map size using eigenvalues: ', som_x_resized, 'x', som_y_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95820eed",
   "metadata": {},
   "source": [
    "## Run the SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a0bee",
   "metadata": {},
   "source": [
    "## Quality check: Quantization Error and Topographic Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ab43a",
   "metadata": {},
   "source": [
    "## Prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d22fe",
   "metadata": {},
   "source": [
    "Select the best epoch - lowest quantization error and topographic error and plot the U matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf7a66",
   "metadata": {},
   "source": [
    "### Prototype maps after dewhitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b3541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406840dc",
   "metadata": {},
   "source": [
    "### Comparison of prototype values with original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e253114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5be0aa8",
   "metadata": {},
   "source": [
    "### Photometry of prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cfc23",
   "metadata": {},
   "source": [
    "Find the data points for each node and construct a dictionary for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f593d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c5f2520",
   "metadata": {},
   "source": [
    "Convert the colors to magnitudes, define the errors "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
