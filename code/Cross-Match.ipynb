{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamental Properties of EMU Radio Sources - Cross-Match Catalogs using NWAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Catalog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emu_catalog_path = \"/home/polaris/Lab_Astro/data/G23-ASKAP-EMUES-master-cat.fits\"\n",
    "emu_mosaic_path = \"/home/polaris/Lab_Astro/data/G23-ASKAP-EMUES-data/G23-EMUES-mosaic.fits\"\n",
    "\n",
    "gama_catalog_path = \"/home/polaris/Lab_Astro/data/gkvInputCatv02.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog_data(catalog_path):\n",
    "    # Open the fits file of the catalog as a fits object\n",
    "    catalog = fits.open(catalog_path)\n",
    "\n",
    "    # Get the data and header of the catalog\n",
    "    catalog_data = catalog[1].data\n",
    "    catalog_header = catalog[1].header\n",
    "    \n",
    "    return catalog_data, catalog_header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "emu_catalog_data, emu_catalog_header = get_catalog_data(emu_catalog_path)\n",
    "gama_catalog_data, gama_catalog_header = get_catalog_data(gama_catalog_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the catalogs for NWAY input\n",
    "The NWAY library has multiple requirements for a catalog to serve as input.\n",
    "1. The fits data table needs to have a extension name, that is used as a prefix for the columns copied to the output catalog\n",
    "2. The fits header of the catalogs needs to have the SKYAREA keyword. This keyword has the area on the sky in square degrees covered by the catalog. Since I don't have the documentation for EMU data, I must calculate the area using the mosaic image.\n",
    "3. The position error needs to be a column with a single value, called positional error, so we need to obtain it from the right ascension and declination errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change extension name\n",
    "This process is also possible using just the NWAY library. Check page 8 of the NWAY documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_hdu_name(fits_file, hdu_index, new_name):\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        # Change the name of the specified HDU\n",
    "        hdul[hdu_index].header['EXTNAME'] = new_name\n",
    "        # Save changes to the FITS file\n",
    "        hdul.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change extension name of EMU survey to \"EMU\" and of GAMA-23 survey to \"G23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_hdu_name(emu_catalog_path, hdu_index=1, new_name=\"EMU\")\n",
    "change_hdu_name(gama_catalog_path, hdu_index=1, new_name=\"G23\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and assign value to SKYAREA keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a fits image of a survey, calculate the area of the survey in degrees^2. The fits image is in pixels and the CDELT1 value on the header is used to rescale to physical units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_survey_area(fits_file):\n",
    "    # Open the FITS file and extract the header\n",
    "    with fits.open(fits_file) as hdul:\n",
    "        header = hdul[0].header\n",
    "        data = hdul[0].data\n",
    "        \n",
    "        # Ensure data is at least 2D (handle multi-dimensional FITS files)\n",
    "        if data.ndim > 2:\n",
    "            data = data[0]  # Take the first frame if it's a multi-frame FITS\n",
    "        \n",
    "        # Get image dimensions\n",
    "        height, width = data.shape[-2:]  # Ensure correct shape indexing\n",
    "        total_pixels = width * height\n",
    "        \n",
    "        # Extract pixel scale from header (if available)\n",
    "        if 'PIXSCALE' in header:\n",
    "            pixel_scale = header['PIXSCALE']  # in arcsec/pixel\n",
    "        elif 'CDELT1' in header and 'CDELT2' in header:\n",
    "            if header['CUNIT1'] == 'deg' and header['CUNIT2'] == 'deg': # Check if units are in degrees\n",
    "                pixel_scale = np.abs(header['CDELT1']) * 3600  # Convert from decimal degrees to arcseconds\n",
    "        else:\n",
    "            raise ValueError(\"Pixel scale not found in FITS header. Check metadata or specify manually.\")\n",
    "        \n",
    "        # Compute the survey area in square arcseconds\n",
    "        area_arcsec2 = total_pixels * (pixel_scale ** 2)\n",
    "        \n",
    "        # Convert to square degrees\n",
    "        area_deg2 = area_arcsec2 / (3600 ** 2)\n",
    "        \n",
    "    print(f\"Total pixels: {total_pixels}\")\n",
    "    print(f\"Pixel scale (arcsec/pixel): {pixel_scale}\")\n",
    "    print(f\"Survey area (deg^2): {area_deg2}\")\n",
    "\n",
    "    return area_deg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixels: 214163136\n",
      "Pixel scale (arcsec/pixel): 2.49999999999984\n",
      "Survey area (deg^2): 103.28083333332012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(103.28083333332012)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_emu_survey = calculate_survey_area(emu_mosaic_path)\n",
    "area_emu_survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the SKYAREA in the FITS header and assign a value to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skyarea_keyword(fits_file, skyarea_value):\n",
    "    \"\"\"\n",
    "    Create the SKYAREA keyword in the FITS header and assign a value to it.\n",
    "\n",
    "    Parameters:\n",
    "    fits_file (str): Path to the FITS file.\n",
    "    skyarea_value (float): Value to assign to the SKYAREA keyword (in square degrees).\n",
    "    \"\"\"\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        # Access the primary header\n",
    "        header = hdul[1].header\n",
    "        \n",
    "        # Add or update the SKYAREA keyword\n",
    "        header['SKYAREA'] = skyarea_value\n",
    "        \n",
    "        # Save changes to the FITS file\n",
    "        hdul.flush()\n",
    "        print(f\"SKYAREA keyword set to {skyarea_value} in {fits_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKYAREA keyword set to 103.28083333332012 in /home/polaris/Lab_Astro/data/G23-ASKAP-EMUES-master-cat.fits.\n",
      "SKYAREA keyword set to 82.7 in /home/polaris/Lab_Astro/data/gkvInputCatv02.fits.\n"
     ]
    }
   ],
   "source": [
    "# Deep ASKAP EMU Survey of the GAMA23 field: Properties of radio sources, Gulay Gurkan et al. (2021), page 3, Table 1\n",
    "area_gama_survey = 82.7\n",
    "\n",
    "\n",
    "create_skyarea_keyword(emu_catalog_path, area_emu_survey)\n",
    "create_skyarea_keyword(gama_catalog_path, area_gama_survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create positional error column and append to fits file\n",
    "This function considers that both the error in RA and DEC are in angular units. The positional error is calculated by using the uncertainty formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positional_error_column(fits_file):\n",
    "    # Open the FITS file and extract data\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        data = hdul[1].data\n",
    "\n",
    "        ra_error = data['E_RA']\n",
    "        dec_error = data['E_DEC']\n",
    "\n",
    "        # Compute the positional error\n",
    "        pos_error_data = np.sqrt(ra_error ** 2 + dec_error ** 2) *3600  # Convert from degrees to arcseconds\n",
    "\n",
    "        # Check if the column 'POS_ERROR' already exists\n",
    "        if 'POS_ERROR' in data.columns.names:\n",
    "            # Update the existing column\n",
    "            data['POS_ERROR'] = pos_error_data\n",
    "            print(\"Updated existing 'POS_ERROR' column with new values.\")\n",
    "        else:\n",
    "            # Create a new column\n",
    "            pos_error_col = fits.Column(name='POS_ERROR', format='D', array=pos_error_data)  # 'D' is for double precision float (64-bit)\n",
    "\n",
    "            # Add the new column to the existing table\n",
    "            new_columns = hdul[1].columns + fits.ColDefs([pos_error_col])\n",
    "            new_hdu = fits.BinTableHDU.from_columns(new_columns)\n",
    "\n",
    "            # Replace the binary table HDU with the updated one\n",
    "            hdul[1] = new_hdu\n",
    "            print(\"Created new 'POS_ERROR' column and added it to the table.\")\n",
    "\n",
    "        # Save changes to the FITS file\n",
    "        hdul.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated existing 'POS_ERROR' column with new values.\n"
     ]
    }
   ],
   "source": [
    "create_positional_error_column(emu_catalog_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix ID Column in EMU survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_id_column_from_source_name(fits_file):\n",
    "    \"\"\"\n",
    "    Reads the 'Source_Name' column, separates it into 'EMUJ' and the number part,\n",
    "    and creates a new column called 'ID' with the number part.\n",
    "\n",
    "    Parameters:\n",
    "    fits_file (str): Path to the FITS file.\n",
    "    \"\"\"\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        data = hdul[1].data\n",
    "\n",
    "        # Ensure the 'Source_Name' column exists\n",
    "        if 'Source_Name' not in data.columns.names:\n",
    "            raise ValueError(\"The FITS file does not contain a 'Source_Name' column.\")\n",
    "\n",
    "        # Extract the 'Source_Name' column\n",
    "        source_names = data['Source_Name']\n",
    "\n",
    "        # Extract the number part from the 'Source_Name' column\n",
    "        id_data = [name.split('EMUJ')[-1] if 'EMUJ' in name else '' for name in source_names]\n",
    "\n",
    "        # Create a new column for the ID\n",
    "        id_col = fits.Column(name='ID', format='20A', array=id_data)  # '20A' for a string column of max length 20\n",
    "\n",
    "        # Add the new column to the existing table\n",
    "        new_columns = hdul[1].columns + fits.ColDefs([id_col])\n",
    "        new_hdu = fits.BinTableHDU.from_columns(new_columns)\n",
    "\n",
    "        # Replace the binary table HDU with the updated one\n",
    "        hdul[1] = new_hdu\n",
    "\n",
    "        # Save changes to the FITS file\n",
    "        hdul.flush()\n",
    "        print(\"Created new 'ID' column with the number part of 'Source_Name'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "name already used as a name or title",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_id_column_from_source_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43memu_catalog_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 27\u001b[0m, in \u001b[0;36mcreate_id_column_from_source_name\u001b[0;34m(fits_file)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Add the new column to the existing table\u001b[39;00m\n\u001b[1;32m     26\u001b[0m new_columns \u001b[38;5;241m=\u001b[39m hdul[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m+\u001b[39m fits\u001b[38;5;241m.\u001b[39mColDefs([id_col])\n\u001b[0;32m---> 27\u001b[0m new_hdu \u001b[38;5;241m=\u001b[39m \u001b[43mfits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBinTableHDU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Replace the binary table HDU with the updated one\u001b[39;00m\n\u001b[1;32m     30\u001b[0m hdul[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m new_hdu\n",
      "File \u001b[0;32m~/miniconda3/envs/labastro/lib/python3.10/site-packages/astropy/io/fits/hdu/table.py:147\u001b[0m, in \u001b[0;36m_TableLikeHDU.from_columns\u001b[0;34m(cls, columns, header, nrows, fill, character_as_bytes, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03mGiven either a `ColDefs` object, a sequence of `Column` objects,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03mor another table HDU or table data (a `FITS_rec` or multi-field\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m``__init__`` may also be passed in as keyword arguments.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m coldefs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_columns_type(columns)\n\u001b[0;32m--> 147\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mFITS_rec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoldefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharacter_as_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcharacter_as_bytes\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m hdu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    151\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata, header\u001b[38;5;241m=\u001b[39mheader, character_as_bytes\u001b[38;5;241m=\u001b[39mcharacter_as_bytes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    153\u001b[0m coldefs\u001b[38;5;241m.\u001b[39m_add_listener(hdu)\n",
      "File \u001b[0;32m~/miniconda3/envs/labastro/lib/python3.10/site-packages/astropy/io/fits/fitsrec.py:343\u001b[0m, in \u001b[0;36mFITS_rec.from_columns\u001b[0;34m(cls, columns, nrows, fill, character_as_bytes)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m>\u001b[39m nrows:\n\u001b[1;32m    341\u001b[0m             nrows \u001b[38;5;241m=\u001b[39m dim\n\u001b[0;32m--> 343\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m*\u001b[39m nrows, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    344\u001b[0m raw_data\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;28mord\u001b[39m(columns\u001b[38;5;241m.\u001b[39m_padding_byte))\n\u001b[1;32m    345\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrecarray(nrows, dtype\u001b[38;5;241m=\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdtype, buf\u001b[38;5;241m=\u001b[39mraw_data)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/labastro/lib/python3.10/site-packages/astropy/utils/decorators.py:836\u001b[0m, in \u001b[0;36mlazyproperty.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    834\u001b[0m         val \u001b[38;5;241m=\u001b[39m obj_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key, _NotFound)\n\u001b[1;32m    835\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NotFound:\n\u001b[0;32m--> 836\u001b[0m             val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m             obj_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[0;32m~/miniconda3/envs/labastro/lib/python3.10/site-packages/astropy/io/fits/column.py:1729\u001b[0m, in \u001b[0;36mColDefs.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1725\u001b[0m             dt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype((dt\u001b[38;5;241m.\u001b[39mbase, dim))\n\u001b[1;32m   1727\u001b[0m     formats\u001b[38;5;241m.\u001b[39mappend(dt)\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformats\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffsets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: name already used as a name or title"
     ]
    }
   ],
   "source": [
    "create_id_column_from_source_name(emu_catalog_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NWAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nway_and_print_output(primary_catalog, secondary_catalog, output_file, primary_err_col, secondary_err_col):\n",
    "    \"\"\"\n",
    "    Run NWAY for cross-matching catalogs and print the output.\n",
    "\n",
    "    Parameters:\n",
    "    primary_catalog (str): Path to the primary catalog FITS file.\n",
    "    secondary_catalog (str): Path to the secondary catalog FITS file.\n",
    "    output_file (str): Path to save the output catalog.\n",
    "    primary_err_col (str): Column name for positional error in the primary catalog.\n",
    "    secondary_err_col (str): Column name for positional error in the secondary catalog.\n",
    "    \"\"\"\n",
    "    # Construct the NWAY command\n",
    "    command = [\n",
    "        'nway.py ',\n",
    "        primary_catalog, \n",
    "        ' :', primary_err_col, ' ',\n",
    "        secondary_catalog,\n",
    "        ' :', secondary_err_col,\n",
    "        \" --out\", output_file,\n",
    "    ]\n",
    "\n",
    "    # Run the NWAY command and capture output\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        print(\"NWAY Output:\")\n",
    "        print(result.stdout)  # Print the standard output from NWAY\n",
    "        if result.stderr:\n",
    "            print(\"NWAY Errors:\")\n",
    "            print(result.stderr)  # Print any errors from NWAY\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running NWAY: {e}\")\n",
    "        print(f\"Standard Output:\\n{e.stdout}\")\n",
    "        print(f\"Standard Error:\\n{e.stderr}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"NWAY is not installed or not found in the system PATH.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labastro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
