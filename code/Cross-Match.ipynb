{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamental Properties of EMU Radio Sources - Cross-Match Catalogs using NWAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Catalog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emu_catalog_path = '/home/polaris/Lab_Astro/data/EMU_data/G23-ASKAP-EMUES-master-cat.fits'\n",
    "emu_mosaic_path = '/home/polaris/Lab_Astro/data/EMU_data/G23-EMUES-mosaic.fits'\n",
    "\n",
    "gama_catalog_path = '/home/polaris/Lab_Astro/data/GAMA_data/gkvInputCatv02.fits'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the catalogs for NWAY input\n",
    "The NWAY library has multiple requirements for a catalog to serve as input.\n",
    "1. The fits data table needs to have a extension name. It is used as a prefix for the columns copied to the output catalog, so each column from each catalog is called \"PREFIXOFCATALOG_NAMEOFCOLUMN\"\n",
    "2. The fits header of the catalogs needs to have the SKYAREA keyword. This keyword has the area on the sky in square degrees covered by the catalog. Since I don't have the documentation for EMU data, I must calculate the area using the mosaic image.\n",
    "3. The position error needs to be a column with a single value, called positional error, so we need to obtain it from the right ascension and declination errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change extension name\n",
    "This process is also possible using just the NWAY library. Check page 8 of the NWAY documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_hdu_name(fits_file, hdu_index, new_name):\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        # Change the name of the specified HDU\n",
    "        hdul[hdu_index].header['EXTNAME'] = new_name\n",
    "        # Save changes to the FITS file\n",
    "        hdul.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change extension name of EMU survey to \"EMU\" and of GAMA-23 survey to \"G23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_hdu_name(emu_catalog_path, hdu_index=1, new_name=\"EMU\")\n",
    "change_hdu_name(gama_catalog_path, hdu_index=1, new_name=\"G23\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and assign value to SKYAREA keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the SKYAREA in the FITS header and assign a value to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skyarea_keyword(fits_file, skyarea_value):\n",
    "    \"\"\"\n",
    "    Create the SKYAREA keyword in the FITS header and assign a value to it.\n",
    "\n",
    "    Parameters:\n",
    "    fits_file (str): Path to the FITS file.\n",
    "    skyarea_value (float): Value to assign to the SKYAREA keyword (in square degrees).\n",
    "    \"\"\"\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        header = hdul[1].header\n",
    "        \n",
    "        header['SKYAREA'] = skyarea_value\n",
    "        \n",
    "        hdul.flush()\n",
    "        print(f\"SKYAREA keyword set to {skyarea_value} in {fits_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKYAREA keyword set to 82.7 in /home/polaris/Lab_Astro/data/EMU_data/G23-ASKAP-EMUES-master-cat.fits.\n",
      "SKYAREA keyword set to 50.6 in /home/polaris/Lab_Astro/data/GAMA_data/gkvInputCatv02.fits.\n"
     ]
    }
   ],
   "source": [
    "# https://www.gama-survey.org/dr4/\n",
    "area_gama_survey = 50.6  # in square degrees\n",
    "\n",
    "# Deep ASKAP EMU Survey of the GAMA23 field: Properties of radio sources, Gulay Gurkan et al. (2021), page 3, Table 1\n",
    "area_emu_survey = 82.7  # in square degrees\n",
    "\n",
    "\n",
    "create_skyarea_keyword(emu_catalog_path, area_emu_survey)\n",
    "create_skyarea_keyword(gama_catalog_path, area_gama_survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create positional error column and append to fits file\n",
    "This function considers that both the error in RA and DEC are in angular units. The positional error is calculated by using the uncertainty formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positional_error_column(fits_file):\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        data = hdul[1].data\n",
    "\n",
    "        ra_error = data['E_RA']\n",
    "        dec_error = data['E_DEC']\n",
    "\n",
    "        # Compute the positional error\n",
    "        pos_error_data = np.sqrt(ra_error ** 2 + dec_error ** 2) *3600  # Convert from degrees to arcseconds\n",
    "\n",
    "        # Check if the column 'POS_ERROR' already exists\n",
    "        if 'POS_ERROR' in data.columns.names:\n",
    "            # Update the existing column\n",
    "            data['POS_ERROR'] = pos_error_data\n",
    "            print(\"Updated existing 'POS_ERROR' column with new values.\")\n",
    "        else:\n",
    "            # Create a new column\n",
    "            pos_error_col = fits.Column(name='POS_ERROR', format='D', array=pos_error_data)  # 'D' is for double precision float (64-bit)\n",
    "\n",
    "            # Add the new column to the existing table\n",
    "            new_columns = hdul[1].columns + fits.ColDefs([pos_error_col])\n",
    "            new_hdu = fits.BinTableHDU.from_columns(new_columns)\n",
    "\n",
    "            # Replace the binary table HDU with the updated one\n",
    "            hdul[1] = new_hdu\n",
    "            print(\"Created new 'POS_ERROR' column and added it to the table.\")\n",
    "\n",
    "        # Save changes to the FITS file\n",
    "        hdul.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated existing 'POS_ERROR' column with new values.\n"
     ]
    }
   ],
   "source": [
    "create_positional_error_column(emu_catalog_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix ID Column in EMU survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_id_column_from_source_name(fits_file):\n",
    "    with fits.open(fits_file, mode='update') as hdul:\n",
    "        data = hdul[1].data\n",
    "\n",
    "        if 'Source_Name' not in data.columns.names:\n",
    "            raise ValueError(\"The FITS file does not contain a 'Source_Name' column.\")\n",
    "        \n",
    "        if 'ID' in data.columns.names:\n",
    "            raise ValueError(\"The FITS file already contains an 'ID' column.\")\n",
    "\n",
    "        source_names = data['Source_Name']\n",
    "\n",
    "        id_data = [name.split('EMUJ')[-1] if 'EMUJ' in name else '' for name in source_names]\n",
    "\n",
    "        id_col = fits.Column(name='ID', format='20A', array=id_data)  # '20A' for a string column of max length 20\n",
    "\n",
    "        new_columns = hdul[1].columns + fits.ColDefs([id_col])\n",
    "        new_hdu = fits.BinTableHDU.from_columns(new_columns)\n",
    "\n",
    "        hdul[1] = new_hdu\n",
    "\n",
    "        hdul.flush()\n",
    "        print(\"Created new 'ID' column with the number part of 'Source_Name'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The FITS file already contains an 'ID' column.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_id_column_from_source_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43memu_catalog_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 9\u001b[0m, in \u001b[0;36mcreate_id_column_from_source_name\u001b[0;34m(fits_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe FITS file does not contain a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource_Name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnames:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe FITS file already contains an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m source_names \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m id_data \u001b[38;5;241m=\u001b[39m [name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMUJ\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMUJ\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m source_names]\n",
      "\u001b[0;31mValueError\u001b[0m: The FITS file already contains an 'ID' column."
     ]
    }
   ],
   "source": [
    "create_id_column_from_source_name(emu_catalog_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labastro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
